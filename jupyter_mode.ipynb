{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendering stylized image. This may take a while...\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcublas.so.8.0 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcudnn.so.5 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcufft.so.8.0 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcuda.so.1 locally\n",
      "I tensorflow/stream_executor/dso_loader.cc:135] successfully opened CUDA library libcurand.so.8.0 locally\n",
      "\n",
      "---- RENDERING SINGLE IMAGE ----\n",
      "\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE3 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.\n",
      "W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.\n",
      "I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:910] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:885] Found device 0 with properties: \n",
      "name: Tesla P4\n",
      "major: 6 minor: 1 memoryClockRate (GHz) 1.1135\n",
      "pciBusID 0000:00:07.0\n",
      "Total memory: 7.43GiB\n",
      "Free memory: 7.32GiB\n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:906] DMA: 0 \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:916] 0:   Y \n",
      "I tensorflow/core/common_runtime/gpu/gpu_device.cc:975] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla P4, pci bus id: 0000:00:07.0)\n",
      "\n",
      "BUILDING VGG-19 NETWORK\n",
      "loading model weights...\n",
      "constructing layers...\n",
      "LAYER GROUP 1\n",
      "--conv1_1 | shape=(1, 512, 512, 64) | weights_shape=(3, 3, 3, 64)\n",
      "--relu1_1 | shape=(1, 512, 512, 64) | bias_shape=(64,)\n",
      "--conv1_2 | shape=(1, 512, 512, 64) | weights_shape=(3, 3, 64, 64)\n",
      "--relu1_2 | shape=(1, 512, 512, 64) | bias_shape=(64,)\n",
      "--pool1   | shape=(1, 256, 256, 64)\n",
      "LAYER GROUP 2\n",
      "--conv2_1 | shape=(1, 256, 256, 128) | weights_shape=(3, 3, 64, 128)\n",
      "--relu2_1 | shape=(1, 256, 256, 128) | bias_shape=(128,)\n",
      "--conv2_2 | shape=(1, 256, 256, 128) | weights_shape=(3, 3, 128, 128)\n",
      "--relu2_2 | shape=(1, 256, 256, 128) | bias_shape=(128,)\n",
      "--pool2   | shape=(1, 128, 128, 128)\n",
      "LAYER GROUP 3\n",
      "--conv3_1 | shape=(1, 128, 128, 256) | weights_shape=(3, 3, 128, 256)\n",
      "--relu3_1 | shape=(1, 128, 128, 256) | bias_shape=(256,)\n",
      "--conv3_2 | shape=(1, 128, 128, 256) | weights_shape=(3, 3, 256, 256)\n",
      "--relu3_2 | shape=(1, 128, 128, 256) | bias_shape=(256,)\n",
      "--conv3_3 | shape=(1, 128, 128, 256) | weights_shape=(3, 3, 256, 256)\n",
      "--relu3_3 | shape=(1, 128, 128, 256) | bias_shape=(256,)\n",
      "--conv3_4 | shape=(1, 128, 128, 256) | weights_shape=(3, 3, 256, 256)\n",
      "--relu3_4 | shape=(1, 128, 128, 256) | bias_shape=(256,)\n",
      "--pool3   | shape=(1, 64, 64, 256)\n",
      "LAYER GROUP 4\n",
      "--conv4_1 | shape=(1, 64, 64, 512) | weights_shape=(3, 3, 256, 512)\n",
      "--relu4_1 | shape=(1, 64, 64, 512) | bias_shape=(512,)\n",
      "--conv4_2 | shape=(1, 64, 64, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--relu4_2 | shape=(1, 64, 64, 512) | bias_shape=(512,)\n",
      "--conv4_3 | shape=(1, 64, 64, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--relu4_3 | shape=(1, 64, 64, 512) | bias_shape=(512,)\n",
      "--conv4_4 | shape=(1, 64, 64, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--relu4_4 | shape=(1, 64, 64, 512) | bias_shape=(512,)\n",
      "--pool4   | shape=(1, 32, 32, 512)\n",
      "LAYER GROUP 5\n",
      "--conv5_1 | shape=(1, 32, 32, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--relu5_1 | shape=(1, 32, 32, 512) | bias_shape=(512,)\n",
      "--conv5_2 | shape=(1, 32, 32, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--relu5_2 | shape=(1, 32, 32, 512) | bias_shape=(512,)\n",
      "--conv5_3 | shape=(1, 32, 32, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--relu5_3 | shape=(1, 32, 32, 512) | bias_shape=(512,)\n",
      "--conv5_4 | shape=(1, 32, 32, 512) | weights_shape=(3, 3, 512, 512)\n",
      "--relu5_4 | shape=(1, 32, 32, 512) | bias_shape=(512,)\n",
      "--pool5   | shape=(1, 16, 16, 512)\n",
      "\n",
      "MINIMIZING LOSS USING: L-BFGS OPTIMIZER\n",
      "RUNNING THE L-BFGS-B CODE\n",
      "\n",
      "           * * *\n",
      "\n",
      "Machine precision = 2.220D-16\n",
      " N =       786432     M =           10\n",
      " This problem is unconstrained.\n",
      "\n",
      "At X0         0 variables are exactly at the bounds\n",
      "\n",
      "At iterate    0    f=  6.20537D+11    |proj g|=  1.12644D+06\n",
      "\n",
      "At iterate   50    f=  2.95347D+09    |proj g|=  1.74343D+04\n",
      "\n",
      "At iterate  100    f=  1.79016D+09    |proj g|=  8.44896D+03\n",
      "\n",
      "At iterate  150    f=  1.53928D+09    |proj g|=  8.25303D+03\n",
      "\n",
      "At iterate  200    f=  1.42347D+09    |proj g|=  2.59128D+03\n",
      "\n",
      "At iterate  250    f=  1.35490D+09    |proj g|=  3.18752D+03\n",
      "\n",
      "At iterate  300    f=  1.31052D+09    |proj g|=  2.49054D+03\n",
      "\n",
      "At iterate  350    f=  1.27871D+09    |proj g|=  2.74452D+03\n",
      "\n",
      "At iterate  400    f=  1.25354D+09    |proj g|=  1.78514D+03\n",
      "\n",
      "At iterate  450    f=  1.23535D+09    |proj g|=  1.34146D+03\n",
      "\n",
      "At iterate  500    f=  1.22032D+09    |proj g|=  1.36356D+03\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "! bash stylize_image.sh ./image_input/lion.jpg ./styles/kandinsky.jpg"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
